package ai

import (
	"bytes"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"

	"github.com/gizensya/discord-friend/internal/config"
)

// VisionClient handles image analysis using AI
type VisionClient struct {
	config     *config.Config
	client     *http.Client
	ollamaURL  string
	openaiKey  string
}

// VisionRequest represents a request to analyze an image
type VisionRequest struct {
	Model    string         `json:"model"`
	Messages []VisionMessage `json:"messages"`
	Stream   bool           `json:"stream"`
}

// VisionMessage represents a message in the vision request
type VisionMessage struct {
	Role    string        `json:"role"`
	Content []ContentItem `json:"content"`
}

// ContentItem represents content that can be text or image
type ContentItem struct {
	Type     string    `json:"type"`
	Text     string    `json:"text,omitempty"`
	ImageURL *ImageURL `json:"image_url,omitempty"`
}

// ImageURL represents an image URL or base64 data
type ImageURL struct {
	URL string `json:"url"`
}

// VisionResponse represents the response from vision AI
type VisionResponse struct {
	Response string `json:"response"`
	Done     bool   `json:"done"`
}

// NewVisionClient creates a new vision AI client
func NewVisionClient(cfg *config.Config) *VisionClient {
	return &VisionClient{
		config:    cfg,
		client:    &http.Client{},
		ollamaURL: cfg.OllamaAPIURL,
		openaiKey: os.Getenv("OPENAI_API_KEY"),
	}
}

// AnalyzeImage analyzes an image file and returns a description
func (v *VisionClient) AnalyzeImage(imagePath, prompt string) (string, error) {
	// Try Ollama first (if available), then fallback to simpler description
	if v.ollamaURL != "" {
		result, err := v.analyzeWithOllama(imagePath, prompt)
		if err == nil {
			return result, nil
		}
		fmt.Printf("âš ï¸ Ollama vision failed, using fallback: %v\n", err)
	}

	// Fallback: basic image info
	return v.getBasicImageInfo(imagePath, prompt)
}

// analyzeWithOllama uses Ollama's vision models (like llava)
func (v *VisionClient) analyzeWithOllama(imagePath, prompt string) (string, error) {
	// Read and encode image
	imageData, err := os.ReadFile(imagePath)
	if err != nil {
		return "", fmt.Errorf("failed to read image: %w", err)
	}

	base64Image := base64.StdEncoding.EncodeToString(imageData)

	// Create vision request
	req := VisionRequest{
		Model: "llava:7b", // Default vision model
		Messages: []VisionMessage{
			{
				Role: "user",
				Content: []ContentItem{
					{
						Type: "text",
						Text: prompt,
					},
					{
						Type: "image_url",
						ImageURL: &ImageURL{
							URL: "data:image/png;base64," + base64Image,
						},
					},
				},
			},
		},
		Stream: false,
	}

	jsonData, err := json.Marshal(req)
	if err != nil {
		return "", fmt.Errorf("failed to marshal request: %w", err)
	}

	// Send request to Ollama
	httpReq, err := http.NewRequest("POST", v.ollamaURL+"/api/chat", bytes.NewBuffer(jsonData))
	if err != nil {
		return "", fmt.Errorf("failed to create request: %w", err)
	}

	httpReq.Header.Set("Content-Type", "application/json")

	resp, err := v.client.Do(httpReq)
	if err != nil {
		return "", fmt.Errorf("failed to send request: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return "", fmt.Errorf("ollama API error %d: %s", resp.StatusCode, string(body))
	}

	var visionResp VisionResponse
	if err := json.NewDecoder(resp.Body).Decode(&visionResp); err != nil {
		return "", fmt.Errorf("failed to decode response: %w", err)
	}

	return visionResp.Response, nil
}

// getBasicImageInfo provides basic image information as fallback
func (v *VisionClient) getBasicImageInfo(imagePath, prompt string) (string, error) {
	// Get file info
	info, err := os.Stat(imagePath)
	if err != nil {
		return "", fmt.Errorf("failed to get image info: %w", err)
	}

	filename := filepath.Base(imagePath)
	sizeKB := float64(info.Size()) / 1024

	// Read image dimensions (basic check)
	file, err := os.Open(imagePath)
	if err != nil {
		return "", fmt.Errorf("failed to open image: %w", err)
	}
	defer file.Close()

	// Basic image analysis
	description := fmt.Sprintf("ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ\n"+
		"ãƒ•ã‚¡ã‚¤ãƒ«: %s (%.1f KB)\n"+
		"æ™‚åˆ»: %s\n\n"+
		"ğŸ’¡ ç”»åƒè§£ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€Ollama LLaVAãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:\n"+
		"`ollama pull llava:7b`",
		filename, sizeKB, info.ModTime().Format("2006-01-02 15:04:05"))

	return description, nil
}

// AnalyzeGameScreen analyzes a game screenshot with gaming context
func (v *VisionClient) AnalyzeGameScreen(imagePath string) (string, error) {
	prompt := `ã“ã‚Œã¯ã‚²ãƒ¼ãƒ ç”»é¢ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã§ã™ã€‚ä»¥ä¸‹ã«ã¤ã„ã¦åˆ†æã—ã¦ãã ã•ã„ï¼š

ğŸ® ã‚²ãƒ¼ãƒ å†…å®¹:
- ä½•ã®ã‚²ãƒ¼ãƒ ã‹ï¼ˆåˆ†ã‹ã‚‹å ´åˆï¼‰
- ç¾åœ¨ã®çŠ¶æ³ã‚„å ´é¢
- ç”»é¢ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ä¸»è¦ãªè¦ç´ 

ğŸ¯ ã‚²ãƒ¼ãƒ çŠ¶æ³:
- ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çŠ¶æ…‹ï¼ˆHPã€ãƒ¬ãƒ™ãƒ«ã€ã‚¢ã‚¤ãƒ†ãƒ ãªã©ï¼‰
- ç¾åœ¨ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³/ç›®æ¨™
- æ³¨ç›®ã™ã¹ããƒã‚¤ãƒ³ãƒˆ

ğŸ’¬ å‹é”ã¨ã—ã¦:
- ã‚²ãƒ¼ãƒ é€²è¡Œã«ã¤ã„ã¦ã®ã‚³ãƒ¡ãƒ³ãƒˆ
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„ææ¡ˆ
- é¢ç™½ãã†ãªç‚¹ã‚„æ°—ã«ãªã‚‹ç‚¹

ç°¡æ½”ã§è¦ªã—ã¿ã‚„ã™ã„æ—¥æœ¬èªã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚`

	return v.AnalyzeImage(imagePath, prompt)
}

// StartScreenAnalysis starts continuous screen analysis
func (v *VisionClient) StartScreenAnalysis(screenshotChan <-chan string, analysisChan chan<- string) {
	go func() {
		defer close(analysisChan)
		
		for screenshot := range screenshotChan {
			analysis, err := v.AnalyzeGameScreen(screenshot)
			if err != nil {
				fmt.Printf("âŒ Screen analysis error: %v\n", err)
				continue
			}
			
			select {
			case analysisChan <- analysis:
				fmt.Printf("ğŸ” Screen analyzed: %s\n", screenshot)
			default:
				// Channel full, skip this analysis
			}
			
			// Clean up screenshot after analysis
			os.Remove(screenshot)
		}
	}()
}