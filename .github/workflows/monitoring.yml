name: Error Monitoring & Health Checks

on:
  push:
    branches: [ "main" ]
  schedule:
    # Run health checks every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      check_type:
        description: 'Type of check to run'
        required: false
        default: 'all'
        type: choice
        options:
        - all
        - security
        - dependencies
        - health

permissions:
  contents: read
  security-events: write
  issues: write

env:
  PYTHON_VERSION: '3.12'

jobs:
  security-monitoring:
    name: Security Monitoring
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'security' || github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety semgrep pip-audit
        
    - name: Run comprehensive security scan
      run: |
        mkdir -p monitoring/security
        
        # Bandit security scan
        echo "Running Bandit security scan..."
        bandit -r src/bot/ -f json -o monitoring/security/bandit-report.json || true
        bandit -r src/bot/ --severity-level medium
        
        # Safety dependency check
        echo "Running Safety dependency check..."
        safety check --json --output monitoring/security/safety-report.json || true
        safety check --short-report
        
        # Pip-audit for additional dependency scanning
        echo "Running pip-audit..."
        pip-audit --format=json --output=monitoring/security/pip-audit-report.json || true
        pip-audit
        
        # Check for secrets in code
        echo "Checking for potential secrets..."
        grep -r -i "password\|secret\|key\|token" src/bot/ --include="*.py" | grep -v "# nosec" | grep -v "test" > monitoring/security/potential-secrets.txt || true
        
        # Check file permissions
        echo "Checking file permissions..."
        find src/bot/ -name "*.py" -perm /002 > monitoring/security/world-writable-files.txt || true
        
    - name: Analyze security results
      run: |
        python -c "
import json
import os
from datetime import datetime

def analyze_security_results():
    '''Analyze security scan results and generate alerts'''
    issues = []
    
    # Check Bandit results
    try:
        with open('monitoring/security/bandit-report.json', 'r') as f:
            bandit_data = json.load(f)
            high_severity = [r for r in bandit_data.get('results', []) if r.get('issue_severity') == 'HIGH']
            medium_severity = [r for r in bandit_data.get('results', []) if r.get('issue_severity') == 'MEDIUM']
            
            if high_severity:
                issues.append(f'âŒ HIGH SEVERITY: {len(high_severity)} high-severity security issues found by Bandit')
            if medium_severity:
                issues.append(f'âš ï¸  MEDIUM SEVERITY: {len(medium_severity)} medium-severity security issues found by Bandit')
    except Exception as e:
        issues.append(f'âš ï¸  Could not analyze Bandit results: {e}')
    
    # Check Safety results
    try:
        with open('monitoring/security/safety-report.json', 'r') as f:
            safety_data = json.load(f)
            vulnerabilities = safety_data.get('vulnerabilities', [])
            
            if vulnerabilities:
                high_vuln = [v for v in vulnerabilities if v.get('severity', '').upper() in ['HIGH', 'CRITICAL']]
                if high_vuln:
                    issues.append(f'âŒ CRITICAL VULNERABILITIES: {len(high_vuln)} critical/high-severity vulnerabilities found')
                else:
                    issues.append(f'âš ï¸  VULNERABILITIES: {len(vulnerabilities)} dependencies with known vulnerabilities')
    except Exception as e:
        issues.append(f'âš ï¸  Could not analyze Safety results: {e}')
    
    # Check for potential secrets
    try:
        with open('monitoring/security/potential-secrets.txt', 'r') as f:
            secrets = f.read().strip()
            if secrets:
                issues.append(f'âš ï¸  POTENTIAL SECRETS: Potential secrets or credentials found in code')
    except Exception:
        pass
    
    # Check for world-writable files
    try:
        with open('monitoring/security/world-writable-files.txt', 'r') as f:
            writable = f.read().strip()
            if writable:
                issues.append(f'âš ï¸  FILE PERMISSIONS: World-writable Python files found')
    except Exception:
        pass
    
    # Generate summary
    summary = {
        'timestamp': datetime.now().isoformat(),
        'issues': issues,
        'severity': 'HIGH' if any('âŒ' in issue for issue in issues) else 'MEDIUM' if issues else 'LOW'
    }
    
    with open('monitoring/security/security-summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    # Print results
    if issues:
        print('\\nðŸ”’ SECURITY MONITORING RESULTS:')
        for issue in issues:
            print(f'  {issue}')
        
        if summary['severity'] == 'HIGH':
            print('\\nâŒ CRITICAL SECURITY ISSUES DETECTED - Immediate action required!')
            exit(1)
        else:
            print('\\nâš ï¸  Security issues detected - Review recommended')
    else:
        print('\\nâœ… No security issues detected')

analyze_security_results()
"

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-monitoring-${{ github.sha }}
        path: monitoring/security/
        retention-days: 90

  dependency-monitoring:
    name: Dependency Health Check
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'dependencies' || github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pip-tools pipdeptree
        cd src/bot
        pip install -r requirements.txt
        
    - name: Analyze dependencies
      run: |
        mkdir -p monitoring/dependencies
        cd src/bot
        
        # Generate dependency tree
        pipdeptree --json > ../../monitoring/dependencies/dependency-tree.json
        pipdeptree > ../../monitoring/dependencies/dependency-tree.txt
        
        # Check for dependency conflicts
        pip check > ../../monitoring/dependencies/pip-check.txt 2>&1 || echo "Dependencies conflicts detected" >> ../../monitoring/dependencies/pip-check.txt
        
        # List outdated packages
        pip list --outdated --format=json > ../../monitoring/dependencies/outdated-packages.json
        
        # Generate requirements diff if previous version exists
        if [ -f requirements.txt.bak ]; then
            diff requirements.txt.bak requirements.txt > ../../monitoring/dependencies/requirements-diff.txt || true
        fi
        
    - name: Analyze dependency health
      run: |
        python -c "
import json
import subprocess
from datetime import datetime

def analyze_dependencies():
    '''Analyze dependency health and detect issues'''
    issues = []
    
    # Check for dependency conflicts
    try:
        with open('monitoring/dependencies/pip-check.txt', 'r') as f:
            pip_check = f.read()
            if 'No broken requirements found' not in pip_check and pip_check.strip():
                issues.append('âŒ DEPENDENCY CONFLICTS: Broken or conflicting dependencies detected')
    except Exception:
        pass
    
    # Check for severely outdated packages
    try:
        with open('monitoring/dependencies/outdated-packages.json', 'r') as f:
            outdated = json.load(f)
            
            critical_outdated = []
            for pkg in outdated:
                current = pkg['version']
                latest = pkg['latest_version']
                # Simple version comparison - flag if major version is very old
                try:
                    current_major = int(current.split('.')[0])
                    latest_major = int(latest.split('.')[0])
                    if latest_major - current_major >= 2:
                        critical_outdated.append(f'{pkg[\"name\"]} ({current} -> {latest})')
                except Exception:
                    pass
            
            if critical_outdated:
                issues.append(f'âš ï¸  SEVERELY OUTDATED: {len(critical_outdated)} packages are multiple major versions behind')
            
            if len(outdated) > 20:
                issues.append(f'âš ï¸  MAINTENANCE: {len(outdated)} packages have updates available')
    except Exception:
        pass
    
    # Check dependency tree for potential issues
    try:
        with open('monitoring/dependencies/dependency-tree.json', 'r') as f:
            tree = json.load(f)
            
            # Count total dependencies
            total_deps = len(tree)
            if total_deps > 100:
                issues.append(f'âš ï¸  BLOAT: Large number of dependencies ({total_deps}) may impact performance')
            
            # Look for duplicate dependencies at different versions
            dep_versions = {}
            for pkg in tree:
                name = pkg['package']['package_name'].lower()
                version = pkg['package']['installed_version']
                if name in dep_versions and dep_versions[name] != version:
                    issues.append(f'âš ï¸  VERSION CONFLICT: Multiple versions of {name} detected')
                dep_versions[name] = version
    except Exception:
        pass
    
    # Generate summary
    summary = {
        'timestamp': datetime.now().isoformat(),
        'issues': issues,
        'severity': 'HIGH' if any('âŒ' in issue for issue in issues) else 'MEDIUM' if any('âš ï¸' in issue for issue in issues) else 'LOW'
    }
    
    with open('monitoring/dependencies/dependency-summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    # Print results
    if issues:
        print('\\nðŸ“¦ DEPENDENCY MONITORING RESULTS:')
        for issue in issues:
            print(f'  {issue}')
    else:
        print('\\nâœ… Dependencies are healthy')

analyze_dependencies()
"

    - name: Upload dependency reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: dependency-monitoring-${{ github.sha }}
        path: monitoring/dependencies/
        retention-days: 30

  health-checks:
    name: System Health Checks
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'health' || github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install psutil
        cd src/bot
        pip install discord.py[voice]==2.3.2 numpy>=2.2.3 soundfile==0.12.1 python-dotenv==1.0.0 sqlalchemy==2.0.23 pydantic httpx aiofiles
        
    - name: Run health checks
      run: |
        mkdir -p monitoring/health
        cd src/bot
        
        python -c "
import sys
import json
import time
import traceback
from datetime import datetime

def run_health_checks():
    '''Run comprehensive health checks'''
    checks = {}
    
    # Test 1: Module import health
    try:
        start_time = time.time()
        import config
        from models.database import init_db, get_database_stats
        from agents import BaseAgent, AgentRole
        from services.agent_manager import AgentManager
        import_time = time.time() - start_time
        
        checks['module_imports'] = {
            'status': 'PASS',
            'import_time': import_time,
            'message': f'All critical modules imported successfully in {import_time:.3f}s'
        }
    except Exception as e:
        checks['module_imports'] = {
            'status': 'FAIL',
            'error': str(e),
            'traceback': traceback.format_exc(),
            'message': 'Failed to import critical modules'
        }
    
    # Test 2: Database connectivity
    try:
        init_db()
        stats = get_database_stats()
        checks['database'] = {
            'status': 'PASS',
            'stats': stats,
            'message': 'Database is accessible and functional'
        }
    except Exception as e:
        checks['database'] = {
            'status': 'FAIL',
            'error': str(e),
            'message': 'Database connectivity issues'
        }
    
    # Test 3: Agent system initialization
    try:
        import asyncio
        
        async def test_agents():
            manager = AgentManager()
            await manager.start()
            
            # Test agent creation
            president = await manager.create_agent('president')
            
            # Test basic functionality
            assert president.agent_id == 'president'
            assert president.role == AgentRole.PRESIDENT
            
            await manager.stop()
            return True
        
        asyncio.run(test_agents())
        checks['agent_system'] = {
            'status': 'PASS',
            'message': 'Agent system initialized and functional'
        }
    except Exception as e:
        checks['agent_system'] = {
            'status': 'FAIL',
            'error': str(e),
            'message': 'Agent system initialization failed'
        }
    
    # Test 4: Configuration validation
    try:
        # Check critical config values
        import config
        critical_configs = ['BOT_TOKEN', 'DIFY_API_KEY', 'DIFY_API_URL']
        missing_configs = []
        
        for config_name in critical_configs:
            if not hasattr(config, config_name) or not getattr(config, config_name):
                missing_configs.append(config_name)
        
        if missing_configs:
            checks['configuration'] = {
                'status': 'WARN',
                'missing_configs': missing_configs,
                'message': f'Missing critical configurations: {missing_configs}'
            }
        else:
            checks['configuration'] = {
                'status': 'PASS',
                'message': 'All critical configurations present'
            }
    except Exception as e:
        checks['configuration'] = {
            'status': 'FAIL',
            'error': str(e),
            'message': 'Configuration validation failed'
        }
    
    # Test 5: Memory and performance check
    try:
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        cpu_percent = process.cpu_percent()
        
        # Check if memory usage is reasonable (under 500MB)
        memory_mb = memory_info.rss / 1024 / 1024
        if memory_mb > 500:
            status = 'WARN'
            message = f'High memory usage detected: {memory_mb:.1f}MB'
        else:
            status = 'PASS'
            message = f'Memory usage normal: {memory_mb:.1f}MB'
        
        checks['performance'] = {
            'status': status,
            'memory_mb': memory_mb,
            'cpu_percent': cpu_percent,
            'message': message
        }
    except Exception as e:
        checks['performance'] = {
            'status': 'FAIL',
            'error': str(e),
            'message': 'Performance check failed'
        }
    
    # Generate overall health status
    failed_checks = [name for name, check in checks.items() if check['status'] == 'FAIL']
    warning_checks = [name for name, check in checks.items() if check['status'] == 'WARN']
    
    if failed_checks:
        overall_status = 'UNHEALTHY'
        overall_message = f'System health check failed: {failed_checks}'
    elif warning_checks:
        overall_status = 'DEGRADED'
        overall_message = f'System health has warnings: {warning_checks}'
    else:
        overall_status = 'HEALTHY'
        overall_message = 'All health checks passed'
    
    health_report = {
        'timestamp': datetime.now().isoformat(),
        'overall_status': overall_status,
        'overall_message': overall_message,
        'checks': checks,
        'summary': {
            'total_checks': len(checks),
            'passed': len([c for c in checks.values() if c['status'] == 'PASS']),
            'warnings': len([c for c in checks.values() if c['status'] == 'WARN']),
            'failed': len([c for c in checks.values() if c['status'] == 'FAIL'])
        }
    }
    
    with open('../../monitoring/health/health-report.json', 'w') as f:
        json.dump(health_report, f, indent=2)
    
    # Print results
    print(f'\\nðŸ¥ SYSTEM HEALTH CHECK: {overall_status}')
    print(f'  {overall_message}')
    print()
    
    for check_name, check_result in checks.items():
        status_emoji = 'âœ…' if check_result['status'] == 'PASS' else 'âš ï¸' if check_result['status'] == 'WARN' else 'âŒ'
        print(f'  {status_emoji} {check_name.upper()}: {check_result[\"message\"]}')
    
    if overall_status == 'UNHEALTHY':
        sys.exit(1)

run_health_checks()
"

    - name: Upload health reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: health-monitoring-${{ github.sha }}
        path: monitoring/health/
        retention-days: 30

  alert-summary:
    name: Generate Monitoring Summary
    runs-on: ubuntu-latest
    needs: [security-monitoring, dependency-monitoring, health-checks]
    if: always()
    
    steps:
    - name: Download all monitoring reports
      uses: actions/download-artifact@v4
      with:
        pattern: "*-monitoring-*"
        merge-multiple: true
        path: monitoring/
        
    - name: Generate comprehensive summary
      run: |
        python -c "
import json
import os
import glob
from datetime import datetime

def generate_monitoring_summary():
    '''Generate comprehensive monitoring summary'''
    summary = {
        'timestamp': datetime.now().isoformat(),
        'commit_sha': os.environ.get('GITHUB_SHA', 'unknown'),
        'workflow_run': os.environ.get('GITHUB_RUN_ID', 'unknown'),
        'categories': {},
        'overall_status': 'HEALTHY',
        'critical_issues': [],
        'warnings': [],
        'recommendations': []
    }
    
    # Process each monitoring category
    for category in ['security', 'dependencies', 'health']:
        summary_file = f'monitoring/{category}-summary.json'
        if os.path.exists(summary_file):
            with open(summary_file, 'r') as f:
                data = json.load(f)
                summary['categories'][category] = data
                
                # Extract issues
                issues = data.get('issues', [])
                for issue in issues:
                    if 'âŒ' in issue:
                        summary['critical_issues'].append(f'{category}: {issue}')
                        if summary['overall_status'] != 'CRITICAL':
                            summary['overall_status'] = 'CRITICAL'
                    elif 'âš ï¸' in issue:
                        summary['warnings'].append(f'{category}: {issue}')
                        if summary['overall_status'] == 'HEALTHY':
                            summary['overall_status'] = 'DEGRADED'
    
    # Generate recommendations
    if summary['critical_issues']:
        summary['recommendations'].append('ðŸš¨ Immediate action required for critical security or system issues')
    if summary['warnings']:
        summary['recommendations'].append('ðŸ“‹ Review and address warning-level issues during next maintenance window')
    if not summary['critical_issues'] and not summary['warnings']:
        summary['recommendations'].append('âœ¨ System is healthy - continue regular monitoring')
    
    with open('monitoring/comprehensive-summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    # Print comprehensive summary
    print('\\nðŸ“Š COMPREHENSIVE MONITORING SUMMARY')
    print(f'Overall Status: {summary[\"overall_status\"]}')
    print(f'Timestamp: {summary[\"timestamp\"]}')
    print()
    
    if summary['critical_issues']:
        print('ðŸš¨ CRITICAL ISSUES:')
        for issue in summary['critical_issues']:
            print(f'  {issue}')
        print()
    
    if summary['warnings']:
        print('âš ï¸  WARNINGS:')
        for warning in summary['warnings']:
            print(f'  {warning}')
        print()
    
    print('ðŸ’¡ RECOMMENDATIONS:')
    for rec in summary['recommendations']:
        print(f'  {rec}')
    
    return summary['overall_status']

status = generate_monitoring_summary()
if status == 'CRITICAL':
    exit(1)
"

    - name: Create GitHub issue for critical problems
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          try {
            const summaryPath = 'monitoring/comprehensive-summary.json';
            const summary = JSON.parse(fs.readFileSync(summaryPath, 'utf8'));
            
            if (summary.critical_issues && summary.critical_issues.length > 0) {
              const issueBody = `## ðŸš¨ Critical System Issues Detected
              
              **Detection Time:** ${summary.timestamp}
              **Commit:** ${summary.commit_sha}
              **Workflow Run:** ${summary.workflow_run}
              
              ### Critical Issues:
              ${summary.critical_issues.map(issue => `- ${issue}`).join('\\n')}
              
              ${summary.warnings.length > 0 ? `### Warnings:
              ${summary.warnings.map(warning => `- ${warning}`).join('\\n')}` : ''}
              
              ### Recommendations:
              ${summary.recommendations.map(rec => `- ${rec}`).join('\\n')}
              
              **This issue was automatically created by the monitoring system.**
              
              Please investigate and resolve these issues immediately.`;
              
              github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `ðŸš¨ Critical System Issues Detected - ${new Date().toISOString().split('T')[0]}`,
                body: issueBody,
                labels: ['critical', 'monitoring', 'automated']
              });
            }
          } catch (error) {
            console.log('Could not create issue:', error);
          }

    - name: Upload comprehensive monitoring summary
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: comprehensive-monitoring-summary
        path: monitoring/comprehensive-summary.json
        retention-days: 90