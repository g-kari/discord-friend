# NOTE: arm images haven't been tested
services:
  faster-whisper-server-cuda:
    image: fedirz/faster-whisper-server:latest-cuda
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    restart: unless-stopped
    ports:
      - 8000:8000
    # runtime: nvidia
    environment:
      - WHISPER__MODEL=kotoba-tech/kotoba-whisper-v1.0-faster
      - WHISPER__INFERENCE_DEVICE=cuda
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ "gpu" ]
  # faster-whisper-server-cpu:
  #   enable: false
  #   image: fedirz/faster-whisper-server:latest-cpu
  #   build:
  #     dockerfile: Dockerfile.cpu
  #     context: .
  #     platforms:
  #       - linux/amd64
  #       - linux/arm64
  #   volumes:
  #     - ~/.cache/huggingface:/root/.cache/huggingface
  #   restart: unless-stopped
  #   ports:
  #     - 8000:8000
  #   develop:
  #     watch:
  #       - path: faster_whisper_server
  #         action: rebuild
  node:
    build:
      context: ./node
      dockerfile: Dockerfile
    volumes:
      - ../..:/workspaces:cached
    network_mode: service:faster-whisper-server-cuda
    tty: true
